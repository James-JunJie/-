##什么是零拷贝？

计算机执行操作时，CPU 不需要先将数据从**一个内存区域复制到另一个内存区域**，从而可以**减少上下文切**换以及 **CPU 的拷贝时间**。

- 零拷贝机制可以减少数据在内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。
- 零拷贝机制可以减少用户进程地址空间和内核地址空间之间因为上下文切换而带来的 CPU 开销。

##1. 物理内存和虚拟内存

由于操作系统的**进程与进程**之间是**共享 CPU 和内存资源**的，因此需要一套完善的**内存管理机制防止进程之间内存泄漏的问题**。为了更加有效地管理内存并减少出错，现代操作系统提供了一种对主存的抽象概念，即是虚拟内存（Virtual Memory）。

虚拟内存为每个进程**提供了一个一致的、私有的地址空间**，它让**每个进程产生了一种自己在独享主存**的错觉（每个进程拥有一片连续完整的内存空间）。

### 1.1. 物理内存

物理内存（Physical memory）：物理内存指通过物理内存条而获得的内存空间。真实存在的插在主板内存槽上的内存条的容量的大小。

### 1.2. 虚拟内存

虚拟内存是计算机系统内存管理的一种技术。 它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间）。

而实际上，虚拟内存通常是被分隔成多个物理内存碎片，还有部分暂时**存储在外部磁盘存储器**上，在需要时进行数据交换，加载到物理内存中来。  

虚拟内存地址和用户进程紧密相关，一般来说**不同进程里的同一个虚拟地址指向的物理地址是不一样的**。

每个进程所能使用的虚拟地址大小和 CPU 位数有关。

在 32 位的系统上，虚拟地址空间大小是 2 ^ 32 = 4G

在 64位系统上，虚拟地址空间大小是 2 ^ 64= 2 ^ 34G。

每个用户进程维护了一个单独的页表（Page Table），虚拟内存和物理内存就是通过这个页表实现地址空间的映射的。

> 下面给出两个进程 A、B 各自的虚拟内存空间以及对应的物理内存之间的地址映射示意图：

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-592088b9b4f2f172d526df017a589d09_720w.jpg)

当进程执行一个程序时，需要先从先内存中读取**该进程的指令**，然后执行，获取指令时用到的就是**虚拟地址**。

这个虚拟地址是程序链接时确定的（内核加载并初始化进程时会调整动态库的地址范围）。为了获取到实际的数据，CPU 需要将虚拟地址转换成物理地址，CPU 转换地址时需要用到进程的页表（Page Table），而页表（Page Table）里面的数据由操作系统维护。

 页表：虚拟地址 ---> 特定的地址空间（物理内存或者磁盘存储空间）

> 每个进程拥有自己的页表（Page Table），和其它进程的页表（Page Table）没有关系。

通过上面的介绍，我们可以简单的将用户进程申请并访问物理内存（或磁盘存储空间）的过程总结如下：

1. 用户进程向操作系统发出内存申请请求
2. 系统会检查进程的虚拟地址空间是否被用完，如果有剩余，给进程分配虚拟地址
3. 系统为这块虚拟地址创建的内存映射（Memory Mapping），并将它放进该进程的页表（Page Table）
4. 系统返回虚拟地址给用户进程，用户进程开始访问该虚拟地址
5. CPU 根据虚拟地址在此进程的页表（Page Table）中找到了相应的内存映射（Memory Mapping），但是这个内存映射（Memory Mapping）没有和物理内存关联，于是产生缺页中断
6. 操作系统收到缺页中断后，分配真正的物理内存并将它关联到页表相应的内存映射（Memory Mapping）。中断处理完成后 CPU 就可以访问内存了
7. 当然缺页中断不是每次都会发生，只有系统觉得有必要延迟分配内存的时候才用的着，也即很多时候在上面的第 3 步系统会分配真正的物理内存并和内存映射（Memory Mapping）进行关联。

####虚拟内存主要有以下的优点：

- **地址空间**：提供更大的地址空间，并且地址空间是连续的，使得程序编写、链接更加简单
- **进程隔离**：不同进程的虚拟地址之间没有关系，所以一个进程的操作不会对其它进程造成影响
- 数据保护：每块虚拟内存都有相应的读写属性，这样就能保护程序的代码段不被修改，数据块不能被执行等，增加了系统的安全性
- 内存映射：有了虚拟内存之后，可以直接映射磁盘上的文件（可执行文件或动态库）到虚拟地址空间。这样可以做到物理内存延时分配，只有在需要读相应的文件的时候，才将它真正的从磁盘上加载到内存中来，而在内存吃紧的时候又可以将这部分内存清空掉，提高物理内存利用效率，并且所有这些对应用程序是都透明的
- **共享内存**：比如动态库只需要在**内存中存储一份**，然后将它映射到不同进程的虚拟地址空间中，让进程觉得自己独占了这个文件。进程间的内存共享也可以通过映射同一块物理内存到进程的不同虚拟地址空间来实现共享
- **物理内存管理**：物理地址空间全部由操作系统管理，进程无法直接分配和回收，从而系统可以更好的利用内存，平衡进程间对内存的需求

##2. 内核空间和用户空间

操作系统的核心是内核，独立于普通的应用程序，**可以访问受保护的内存空间**，也有**访问底层硬件设备的权限**。

为了避免用户进程直接操作内核，保证内核安全，操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space），一部分是用户空间（User-space）。 

* 内核模块运行在内核空间，对应的进程处于内核态

* 而用户程序运行在用户空间，对应的进程处于用户态。

核进程和用户进程所占的虚拟内存比例是 1:3

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-9a158fa2659d5baaea50be32c20e6dba_720w.jpg)

### 2.1. 内核空间

内核空间总是驻留在内存中，它是为操作系统的内核保留的。应用程序是不允许直接在该区域进行读写或直接调用内核代码定义的函数的。上图左侧区域为内核进程对应的虚拟内存，按访问权限可以分为进程私有和进程共享两块区域。

- 进程私有的虚拟内存：每个进程都有单独的内核栈、页表、task 结构以及 mem_map 结构等。
- 进程共享的虚拟内存：属于所有进程共享的内存区域，包括物理存储器、内核数据和内核代码区域。



### 2.2. 用户空间

每个普通的用户进程都有一个单独的用户空间，因此要进行系统调用的时候，就要将进程切换到内核态才行。

用户空间包括以下几个内存区域：

- 运行时栈：由编译器自动释放，存放函数的参数值，局部变量和方法返回值等。每当一个函数被调用时，该函数的返回类型和一些调用的信息被存储到栈顶，调用结束后调用信息会被弹出弹出并释放掉内存。栈区是从高地址位向低地址位增长的，是一块连续的内在区域，最大容量是由系统预先定义好的，申请的栈空间超过这个界限时会提示溢出，用户能从栈中获取的空间较小。
- 运行时堆：用于存放进程运行中被动态分配的内存段，位于 BSS 和栈中间的地址位。由卡发人员申请分配（malloc）和释放（free）。堆是从低地址位向高地址位增长，采用链式存储结构。频繁地 malloc/free 造成内存空间的不连续，产生大量碎片。当申请堆空间时，库函数按照一定的算法搜索可用的足够大的空间。因此堆的效率比栈要低的多。
- 代码段：存放 CPU 可以执行的机器指令，该部分内存只能读不能写。通常代码区是共享的，即其它执行程序可调用它。假如机器中有数个进程运行相同的一个程序，那么它们就可以使用同一个代码段。
- 未初始化的数据段：存放未初始化的全局变量，BSS 的数据在程序开始执行之前被初始化为 0 或 NULL。
- 已初始化的数据段：存放已初始化的全局变量，包括静态全局变量、静态局部变量以及常量。
- 内存映射区域：例如将动态库，共享内存等虚拟空间的内存映射到物理空间的内存，一般是 mmap 函数所分配的虚拟内存空间。

##4. Linux I/O读写方式

* 轮询： 基于死循环对 I/O 端口进行不断检测。
* I/O中断：指当数据到达时，磁盘主动向 CPU 发起中断请求，由 **CPU 自身负责数据的传输过程**。
* DMA传输： DMA 将数据从**磁盘控制器缓冲区**拷贝到**内核缓冲区**。降低了 CPU 资源消耗。

### 4.1. I/O中断原理

在 DMA 技术出现之前，应用程序与磁盘之间的 I/O 操作都是通过 CPU 的中断完成的。

每次用户进程读取磁盘数据时，都需要 CPU 中断，然后发起 I/O 请求等待数据读取和拷贝完成，每次的 I/O 中断都导致 CPU 的上下文切换。

步骤：

1. 用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回。
2. CPU 在接收到指令以后对磁盘发起 I/O 请求，将磁盘数据先放入磁盘控制器缓冲区。
3. 数据准备完成以后，磁盘向 CPU 发起 I/O 中断。
4. CPU 收到 I/O 中断以后将磁盘缓冲区中的数据拷贝到内核缓冲区，然后再从内核缓冲区拷贝到用户缓冲区。
5. 用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟。

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-0b46e37f599e0855925a39201add483a_720w.jpg)

### 4.2. DMA传输原理

DMA 的全称叫**直接内存存取**（Direct Memory Access），是一种允许外围设备（硬件子系统）直接访问系统主内存的机制。

也就是说，基于 DMA 访问方式， 减少了cpu的使用。

步骤：

1. 用户进程向 CPU 发起 **read 系统**调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回。
2. CPU 在接收到指令以后对 DMA 磁盘控制器发起调度指令。
3. DMA 磁盘控制器对磁盘发起 I/O 请求，将磁盘数据先放入磁盘控制器缓冲区，CPU 全程不参与此过程。
4. 数据读取完成后，DMA 磁盘控制器会接受到磁盘的通知，将数据从磁盘控制器缓冲区拷贝到内核缓冲区。
5. DMA 磁盘控制器向 CPU 发出数据读完的信号，由 CPU 负责将数据从内核缓冲区拷贝到用户缓冲区。
6. 用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟。

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-8894982f1c09259e2959acddc9f095e7_720w.jpg)

### 5. 传统I/O方式

为了更好的理解零拷贝解决的问题，我们首先了解一下传统 I/O 方式存在的问题。在 Linux 系统中，传统的访问方式是通过 write() 和 read() 两个系统调用实现。

下图分别对应传统 I/O 操作的数据读写流程，整个过程涉及

* 4 次拷贝
  *  2 次 CPU 拷贝
  * 2 次 DMA 拷贝
*  4 次上下文切换

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-18e66cbb4e06d1f13e4335898c7b8e8c_720w.jpg)

### 5.1. 传统读操作

用户程序执行 read 系统调用读取一块数据，在，就直接从内存中读取数据；

数据不存在，则先将数据从磁盘加载数据到内核空间的读缓存（read buffer）中，再从读缓存拷贝到用户进程的页内存中。

read 系统调用会触发 

* 2 次上下文切换：read() 用户到内核态发起调用，read执行完成内核态--->用户态

* 1 次 DMA 拷贝: 主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。

* 1 次 CPU 拷贝: 内核空间的**读缓冲区（**read buffer）--->  用户空间（user space）的**用户缓冲区**（user buffer）

### 5.2. 传统写操作

同理：

write 系统调用会触发 

* 2 次上下文切换：write() 用户到内核态发起调用，read执行完成内核态--->用户态

* 1 次 DMA 拷贝:  内核缓冲区----->网卡

* 1 次 CPU 拷贝:   用户空间（user space）的**用户缓冲区**（user buffer） ->  内核空间的**写缓冲区（**read buffer

### 6. 零拷贝方式

* 用户态直接 I/O

* 减少数据拷贝次数

* 写时复制技术。

### 6.1. 用户态直接I/O

直接绕过内核，对硬件设备传输

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-4cb0f465ebeb7ff0f5e31e8d3f790c80_720w.jpg)

### 6.2. mmap + write

省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程

* 4 次上下文切换： 系统调用

* 1 次 CPU 拷贝 ：读内核缓存区 - --> 写内核缓冲区

* 2 次 DMA 拷贝

用户程序读写数据的流程如下：

![preview](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-28463616753963ac9f189ce23a485e2d_r.jpg)

### 6.3. sendfile

与 mmap 内存映射方式不同的是， sendfile 调用中 I/O 数据对用户空间是完全不可见的。也就是说，这是一次完全意义上的数据传输过程。

* 2 次上下文切换： 系统调用

* 1 次 CPU 拷贝 ：读内核缓存区 - --> 写内核缓冲区

* 2 次 DMA 拷贝

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-48132735369375701f3d8ac1d6029c2a_720w.jpg)



### 6.5. splice

sendfile 只适用于将数据从文件拷贝到 socket 套接字上。

在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作。

* 2次上下文切换： 系统调用

* 0次 CPU 拷贝 ： 建立管道传输数据。

* 2 次 DMA 拷贝: 

![img](https://ljjblog.oss-cn-beijing.aliyuncs.com/img/v2-37cf7a8b129183c24c7b524d3fee1a29_720w.jpg)



### 6.6. 写时复制

内核缓冲区被进程所共享，**多个进程想要这个共享区进行 write 操作**，那么就会对共享区中的数据造成破坏。

写时复制： 当多个进程共享同一块数据时，进程**数据进行修改**，那么就需要将其**拷贝到自己的进程地址空间中**。这样做并不影响其他进程对这块数据的操作，每个进程要**修改**的时候才会进行拷贝，所以叫**写时拷贝**。 

### 8. Java NIO零拷贝实现

在 Java NIO 中的通道（Channel）就相当于操作系统的内核空间（kernel space）的缓冲区，而缓冲区（Buffer）对应的相当于操作系统的用户空间（user space）中的用户缓冲区（user buffer）。

- 通道（Channel）是全双工的（双向传输），它既可能是读缓冲区（read buffer），也可能是网络缓冲区（socket buffer）。
- 缓冲区（Buffer）分为堆内存（HeapBuffer）和堆外内存（DirectBuffer），这是通过 malloc() 分配出来的用户态内存。

堆外内存（DirectBuffer）在使用后需要应用程序手动回收，而堆内存（HeapBuffer）的数据在 GC 时可能会被自动回收。因此，在使用 HeapBuffer 读写数据时，为了避免缓冲区数据因为 GC 而丢失，NIO 会先把 HeapBuffer 内部的数据拷贝到一个临时的 DirectBuffer 中的本地内存（native memory），这个拷贝涉及到 sun.misc.Unsafe.copyMemory() 的调用，背后的实现原理与 memcpy() 类似。 最后，将临时生成的 DirectBuffer 内部的数据的内存地址传给 I/O 调用函数，这样就避免了再去访问 Java 对象处理 I/O 读写。